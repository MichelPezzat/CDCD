# change from o4
model:
  target: synthesis.modeling.models.d2m.D2M
  params:
    content_info: {key: music}
    condition_info_genre: {key: genre}
    hop_level: 'top' # top (128), or middle (32), bottom (8) 
    vqvae_load_path: './synthesis/modeling/models/vqvae.pt'

    content_codec_config: 
      target: synthesis.modeling.codecs.music_codec.jukebox_vqvae.VQVAE


    diffusion_config:      
      target: synthesis.modeling.transformers.tauLDR.ConditionalAux
      params:
        ratio_eps: 80
        nll_weigth: 0.001      # init_type = fix or cos or linear 
        min_time: 5.0e-4
        one_forward_pass: True   # the loss weight on mask region and non-mask region
        condition_dim: 345 # 2s
        #vqvae_load_path: './synthesis/modeling/models/vqvae.pt'
        #hop_level: 'top' 
        transformer_config:
          target: synthesis.modeling.transformers.transformer_utils.UniformRateText2ImageTransformer
          params:
            attn_type: 'selfcross'
            n_layer: 19
            condition_seq_len: 77    ###### 77 for clip and 256 for dalle
            content_seq_len: 1378  # 8s * 22050 / 128
            content_spatial_size: [1, 1378]
            n_embd: 1024 # the dim of embedding dims
            condition_dim: 1024
            n_head: 16 
            attn_pdrop: 0.0
            resid_pdrop: 0.0
            block_activate: GELU2
            timestep_type: 'adalayernorm'    # adainsnorm or adalayernorm and abs
            temb_dim: 1024
            time_scale_factor: 1000
            mlp_hidden_times: 4
            rate_const: 0.03
        condition_emb_config:
          target: synthesis.modeling.embeddings.genre_embedding.GenreEmbedding
          params:
            num_embed: 10 # number of music genres
            embed_dim: 256
        content_emb_config:
          target: synthesis.modeling.embeddings.d2m_mask_music_embedding.D2MMaskMusicEmbedding
          params:
            num_embed: 2048  #jukebox codebooksize
            spatial_size: !!python/tuple [1, 1033]
            embed_dim: 1024
            trainable: True
            pos_emb_type: embedding

solver:
  base_lr: 3.0e-6
  adjust_lr: none # not adjust lr according to total batch_size
  max_epochs: 100
  save_epochs: 2
  validation_epochs: 5
  sample_iterations: epoch  # epoch #30000      # how many iterations to perform sampling once ?
  print_specific_things: True

  # config for ema
  ema:
    decay: 0.99
    update_interval: 25
    device: cpu

  clip_grad_norm:
    target: synthesis.engine.clip_grad_norm.ClipGradNorm
    params:
      start_iteration: 0
      end_iteration: 5000
      max_norm: 0.5
  optimizers_and_schedulers: # a list of configures, so we can config several optimizers and schedulers
  - name: none # default is None
    optimizer:
      target: torch.optim.AdamW
      params: 
        betas: !!python/tuple [0.9, 0.96]
        weight_decay: 4.5e-2
            # target: ZeroRedundancyOptimizer
            # optimizer_class: torch.optim.AdamW
            # params:
            # betas: !!python/tuple [0.9, 0.96]
            # weight_decay: 4.5e-2
    scheduler:
      step_iteration: 1
      target: synthesis.engine.lr_scheduler.ReduceLROnPlateauWithWarmup
      params:
        factor: 0.5
        patience: 60000
        min_lr: 1.0e-6
        threshold: 1.0e-1
        threshold_mode: rel
        warmup_lr: 2.0e-4 # the lr to be touched after warmup
        warmup: 1000 

dataloader:
  # data_root: data
  data_root: /zhuye/data/aistplus
  batch_size: 2
  num_workers: 4
  train_datasets: # a list of configures, so we can combine several schedulers
    - target: synthesis.data.aist_dataset.AISTDataset
      params:
        # data_root: /zhuye/data/aistplus
        phase: train
        audio_files: './data/audios_train.txt'
        genre_label: './data/genres_train.npy'
        augment: True
        segment_length: 8

  validation_datasets:
    - target: synthesis.data.aist_dataset.AISTDataset
      params:
        # data_root: /zhuye/data/aistplus
        phase: val
        audio_files: './data/audios_test.txt'
        genre_label: './data/genres_test.npy'
        augment: False
        segment_length: 8
